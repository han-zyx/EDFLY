2025-01-28 08:31:31,092 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - --------------------------------------------------------------------------------
2025-01-28 08:31:31,093 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Preconfiguration: 
2025-01-28 08:31:31,093 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - 


RESOURCE_PARAMS extraction logs:
jvm_params: -Xmx536870902 -Xms536870902 -XX:MaxDirectMemorySize=268435458 -XX:MaxMetaspaceSize=268435456
dynamic_configs: -D taskmanager.memory.network.min=134217730b -D taskmanager.cpu.cores=1.0 -D taskmanager.memory.task.off-heap.size=0b -D taskmanager.memory.jvm-metaspace.size=268435456b -D external-resources=none -D taskmanager.memory.jvm-overhead.min=201326592b -D taskmanager.memory.framework.off-heap.size=134217728b -D taskmanager.memory.network.max=134217730b -D taskmanager.memory.framework.heap.size=134217728b -D taskmanager.memory.managed.size=536870920b -D taskmanager.memory.task.heap.size=402653174b -D taskmanager.numberOfTaskSlots=1 -D taskmanager.memory.jvm-overhead.max=201326592b
logs: WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.
INFO  [] - Loading configuration property: jobmanager.rpc.address, localhost
INFO  [] - Loading configuration property: jobmanager.rpc.port, 6123
INFO  [] - Loading configuration property: jobmanager.memory.process.size, 1600m
INFO  [] - Loading configuration property: taskmanager.memory.process.size, 1728m
INFO  [] - Loading configuration property: taskmanager.numberOfTaskSlots, 1
INFO  [] - Loading configuration property: parallelism.default, 1
INFO  [] - Loading configuration property: jobmanager.execution.failover-strategy, region
INFO  [] - The derived from fraction jvm overhead memory (172.800mb (181193935 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead
INFO  [] - Final TaskExecutor Memory configuration:
INFO  [] -   Total Process Memory:          1.688gb (1811939328 bytes)
INFO  [] -     Total Flink Memory:          1.250gb (1342177280 bytes)
INFO  [] -       Total JVM Heap Memory:     512.000mb (536870902 bytes)
INFO  [] -         Framework:               128.000mb (134217728 bytes)
INFO  [] -         Task:                    384.000mb (402653174 bytes)
INFO  [] -       Total Off-heap Memory:     768.000mb (805306378 bytes)
INFO  [] -         Managed:                 512.000mb (536870920 bytes)
INFO  [] -         Total JVM Direct Memory: 256.000mb (268435458 bytes)
INFO  [] -           Framework:             128.000mb (134217728 bytes)
INFO  [] -           Task:                  0 bytes
INFO  [] -           Network:               128.000mb (134217730 bytes)
INFO  [] -     JVM Metaspace:               256.000mb (268435456 bytes)
INFO  [] -     JVM Overhead:                192.000mb (201326592 bytes)

2025-01-28 08:31:31,093 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - --------------------------------------------------------------------------------
2025-01-28 08:31:31,093 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Starting TaskManager (Version: 1.13.6, Scala: 2.12, Rev:b2ca390, Date:2022-02-03T14:54:22+01:00)
2025-01-28 08:31:31,093 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  OS current user: hansaka
2025-01-28 08:31:31,093 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Current Hadoop/Kerberos user: <no hadoop dependency found>
2025-01-28 08:31:31,093 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  JVM: OpenJDK 64-Bit Server VM - Ubuntu - 11/11.0.25+9-post-Ubuntu-1ubuntu122.04
2025-01-28 08:31:31,093 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Maximum heap size: 512 MiBytes
2025-01-28 08:31:31,093 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  JAVA_HOME: (not set)
2025-01-28 08:31:31,094 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  No Hadoop Dependency available
2025-01-28 08:31:31,094 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  JVM Options:
2025-01-28 08:31:31,094 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -XX:+UseG1GC
2025-01-28 08:31:31,094 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Xmx536870902
2025-01-28 08:31:31,094 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Xms536870902
2025-01-28 08:31:31,094 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -XX:MaxDirectMemorySize=268435458
2025-01-28 08:31:31,094 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -XX:MaxMetaspaceSize=268435456
2025-01-28 08:31:31,094 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlog.file=/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/log/flink-hansaka-taskexecutor-0-hansaka-ubuntu.log
2025-01-28 08:31:31,094 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlog4j.configuration=file:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/conf/log4j.properties
2025-01-28 08:31:31,094 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlog4j.configurationFile=file:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/conf/log4j.properties
2025-01-28 08:31:31,094 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlogback.configurationFile=file:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/conf/logback.xml
2025-01-28 08:31:31,094 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Program Arguments:
2025-01-28 08:31:31,095 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --configDir
2025-01-28 08:31:31,095 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     /home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/conf
2025-01-28 08:31:31,095 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-01-28 08:31:31,095 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.network.min=134217730b
2025-01-28 08:31:31,095 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-01-28 08:31:31,095 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.cpu.cores=1.0
2025-01-28 08:31:31,095 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-01-28 08:31:31,095 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.task.off-heap.size=0b
2025-01-28 08:31:31,095 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-01-28 08:31:31,095 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.jvm-metaspace.size=268435456b
2025-01-28 08:31:31,095 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-01-28 08:31:31,095 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     external-resources=none
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.jvm-overhead.min=201326592b
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.framework.off-heap.size=134217728b
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.network.max=134217730b
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.framework.heap.size=134217728b
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.managed.size=536870920b
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.task.heap.size=402653174b
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.numberOfTaskSlots=1
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.jvm-overhead.max=201326592b
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Classpath: /home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/flink-csv-1.13.6.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/flink-json-1.13.6.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/flink-shaded-zookeeper-3.4.14.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/flink-table_2.12-1.13.6.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/flink-table-blink_2.12-1.13.6.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/log4j-1.2-api-2.17.1.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/log4j-api-2.17.1.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/log4j-core-2.17.1.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/log4j-slf4j-impl-2.17.1.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/flink-dist_2.12-1.13.6.jar:::
2025-01-28 08:31:31,096 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - --------------------------------------------------------------------------------
2025-01-28 08:31:31,097 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Registered UNIX signal handlers for [TERM, HUP, INT]
2025-01-28 08:31:31,099 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Maximum number of open file descriptors is 1048576.
2025-01-28 08:31:31,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, localhost
2025-01-28 08:31:31,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.port, 6123
2025-01-28 08:31:31,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 1600m
2025-01-28 08:31:31,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 1728m
2025-01-28 08:31:31,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 1
2025-01-28 08:31:31,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 1
2025-01-28 08:31:31,105 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.execution.failover-strategy, region
2025-01-28 08:31:31,135 INFO  org.apache.flink.core.fs.FileSystem                          [] - Hadoop is not in the classpath/dependencies. The extended set of supported File Systems via Hadoop is not available.
2025-01-28 08:31:31,167 INFO  org.apache.flink.runtime.security.modules.HadoopModuleFactory [] - Cannot create Hadoop Security Module because Hadoop cannot be found in the Classpath.
2025-01-28 08:31:31,180 INFO  org.apache.flink.runtime.security.modules.JaasModule         [] - Jaas file will be created as /tmp/jaas-986149747405090698.conf.
2025-01-28 08:31:31,185 INFO  org.apache.flink.runtime.security.contexts.HadoopSecurityContextFactory [] - Cannot install HadoopSecurityContext because Hadoop cannot be found in the Classpath.
2025-01-28 08:31:31,221 INFO  org.apache.flink.configuration.Configuration                 [] - Config uses fallback configuration key 'jobmanager.rpc.address' instead of key 'rest.address'
2025-01-28 08:31:31,230 INFO  org.apache.flink.runtime.util.LeaderRetrievalUtils           [] - Trying to select the network interface and address to use by connecting to the leading JobManager.
2025-01-28 08:31:31,230 INFO  org.apache.flink.runtime.util.LeaderRetrievalUtils           [] - TaskManager will try to connect for PT10S before falling back to heuristics
2025-01-28 08:31:31,678 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Trying to connect to address localhost/127.0.0.1:6123
2025-01-28 08:31:31,679 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Failed to connect from address 'hansaka-ubuntu/192.168.1.12': Connection refused (Connection refused)
2025-01-28 08:31:31,679 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Failed to connect from address '/127.0.0.1': Connection refused (Connection refused)
2025-01-28 08:31:31,680 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Failed to connect from address '/172.17.0.1': Connection refused (Connection refused)
2025-01-28 08:31:31,680 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Failed to connect from address '/2402:d000:8138:11f4:5373:bf70:a38c:fda7%enp3s0': Network is unreachable (connect failed)
2025-01-28 08:31:31,680 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Failed to connect from address '/2402:d000:8138:11f4:d089:7886:26b8:65eb%enp3s0': Network is unreachable (connect failed)
2025-01-28 08:31:31,680 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Failed to connect from address '/fe80:0:0:0:1b95:db6c:d1c9:76f9%enp3s0': Network is unreachable (connect failed)
2025-01-28 08:31:31,680 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Failed to connect from address '/192.168.1.12': Connection refused (Connection refused)
2025-01-28 08:31:31,680 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Failed to connect from address '/0:0:0:0:0:0:0:1%lo': Network is unreachable (connect failed)
2025-01-28 08:31:31,681 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Failed to connect from address '/127.0.0.1': Connection refused (Connection refused)
2025-01-28 08:31:31,681 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Failed to connect from address '/172.17.0.1': Connection refused (Connection refused)
2025-01-28 08:31:31,681 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Failed to connect from address '/2402:d000:8138:11f4:5373:bf70:a38c:fda7%enp3s0': Network is unreachable (connect failed)
2025-01-28 08:31:31,681 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Failed to connect from address '/2402:d000:8138:11f4:d089:7886:26b8:65eb%enp3s0': Network is unreachable (connect failed)
2025-01-28 08:31:31,681 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Failed to connect from address '/fe80:0:0:0:1b95:db6c:d1c9:76f9%enp3s0': Network is unreachable (connect failed)
2025-01-28 08:31:31,681 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Failed to connect from address '/192.168.1.12': Connection refused (Connection refused)
2025-01-28 08:31:31,681 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Failed to connect from address '/0:0:0:0:0:0:0:1%lo': Network is unreachable (connect failed)
2025-01-28 08:31:31,682 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Failed to connect from address '/127.0.0.1': Connection refused (Connection refused)
2025-01-28 08:31:32,082 INFO  org.apache.flink.runtime.net.ConnectionUtils                 [] - Trying to connect to address localhost/127.0.0.1:6123
2025-01-28 08:31:32,082 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - TaskManager will use hostname/address 'hansaka-ubuntu' (192.168.1.12) for communication.
2025-01-28 08:31:32,088 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address 192.168.1.12:0, bind address 0.0.0.0:0.
2025-01-28 08:31:32,488 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2025-01-28 08:31:32,508 INFO  akka.remote.Remoting                                         [] - Starting remoting
2025-01-28 08:31:32,600 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink@192.168.1.12:33167]
2025-01-28 08:31:32,668 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink@192.168.1.12:33167
2025-01-28 08:31:32,681 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No metrics reporter configured, no metrics will be exposed/reported.
2025-01-28 08:31:32,684 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address 192.168.1.12:0, bind address 0.0.0.0:0.
2025-01-28 08:31:32,698 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2025-01-28 08:31:32,702 INFO  akka.remote.Remoting                                         [] - Starting remoting
2025-01-28 08:31:32,709 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink-metrics@192.168.1.12:37977]
2025-01-28 08:31:32,717 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink-metrics@192.168.1.12:37977
2025-01-28 08:31:32,729 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService_192.168.1.12:33167-1e7ff6 .
2025-01-28 08:31:32,737 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Created BLOB cache storage directory /tmp/blobStore-86053edb-daaa-483f-b458-151c8c0ef3e5
2025-01-28 08:31:32,739 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Created BLOB cache storage directory /tmp/blobStore-332d0cce-491f-461b-9c21-2ff7189e1e48
2025-01-28 08:31:32,742 INFO  org.apache.flink.runtime.externalresource.ExternalResourceUtils [] - Enabled external resources: []
2025-01-28 08:31:32,743 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Starting TaskManager with ResourceID: 192.168.1.12:33167-1e7ff6
2025-01-28 08:31:32,760 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/tmp': total 115 GB, usable 11 GB (9.57% usable)
2025-01-28 08:31:32,762 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /tmp/flink-io-afe4d720-a9a2-4a8e-afc6-90ad45690b64 for spill files.
2025-01-28 08:31:32,772 INFO  org.apache.flink.runtime.io.network.netty.NettyConfig        [] - NettyConfig [server address: /0.0.0.0, server port: 0, ssl enabled: false, memory segment size (bytes): 32768, transport type: AUTO, number of server threads: 1 (manual), number of client threads: 1 (manual), server connect backlog: 0 (use Netty's default), client connect timeout (sec): 120, send/receive buffer size (bytes): 0 (use Netty's default)]
2025-01-28 08:31:32,775 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /tmp/flink-netty-shuffle-1a44cc63-6636-4749-9064-3685d8bb8542 for spill files.
2025-01-28 08:31:32,867 INFO  org.apache.flink.runtime.io.network.buffer.NetworkBufferPool [] - Allocated 128 MB for network buffer pool (number of memory segments: 4096, bytes per segment: 32768).
2025-01-28 08:31:32,878 INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment  [] - Starting the network environment and its components.
2025-01-28 08:31:32,920 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Transport type 'auto': using EPOLL.
2025-01-28 08:31:32,920 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Successful initialization (took 42 ms).
2025-01-28 08:31:32,923 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Transport type 'auto': using EPOLL.
2025-01-28 08:31:32,944 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Successful initialization (took 22 ms). Listening on SocketAddress /0:0:0:0:0:0:0:0%0:44153.
2025-01-28 08:31:32,946 INFO  org.apache.flink.runtime.taskexecutor.KvStateService         [] - Starting the kvState service and its components.
2025-01-28 08:31:32,963 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2025-01-28 08:31:32,979 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Start job leader service.
2025-01-28 08:31:32,980 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /tmp/flink-dist-cache-f1168690-7396-43d9-9587-c571f48349f4
2025-01-28 08:31:32,981 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Connecting to ResourceManager akka.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000).
2025-01-28 08:31:33,102 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Resolved ResourceManager address, beginning registration
2025-01-28 08:31:33,187 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Successful registration at resource manager akka.tcp://flink@localhost:6123/user/rpc/resourcemanager_* under registration id cb6f784effbed8049e409b118426ed79.
2025-01-28 08:32:30,715 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request d2c93e2be0aceb0ecda0478f437ae702 for job 64a213c6b566eaf4a6e1a5e76640b445 from resource manager with leader id 00000000000000000000000000000000.
2025-01-28 08:32:30,719 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for d2c93e2be0aceb0ecda0478f437ae702.
2025-01-28 08:32:30,720 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 64a213c6b566eaf4a6e1a5e76640b445 for job leader monitoring.
2025-01-28 08:32:30,721 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager akka.tcp://flink@localhost:6123/user/rpc/jobmanager_2 with leader id 00000000-0000-0000-0000-000000000000.
2025-01-28 08:32:30,734 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-01-28 08:32:30,767 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager akka.tcp://flink@localhost:6123/user/rpc/jobmanager_2 for job 64a213c6b566eaf4a6e1a5e76640b445.
2025-01-28 08:32:30,768 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 64a213c6b566eaf4a6e1a5e76640b445.
2025-01-28 08:32:30,771 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 64a213c6b566eaf4a6e1a5e76640b445.
2025-01-28 08:32:30,793 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot d2c93e2be0aceb0ecda0478f437ae702.
2025-01-28 08:32:30,796 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot d2c93e2be0aceb0ecda0478f437ae702.
2025-01-28 08:32:30,823 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (64d05c2a988b298cf441ad83dec990f9), deploy into slot with allocation id d2c93e2be0aceb0ecda0478f437ae702.
2025-01-28 08:32:30,824 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (64d05c2a988b298cf441ad83dec990f9) switched from CREATED to DEPLOYING.
2025-01-28 08:32:30,828 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (64d05c2a988b298cf441ad83dec990f9) [DEPLOYING].
2025-01-28 08:32:30,832 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading 64a213c6b566eaf4a6e1a5e76640b445/p-b3b6e47ee9f7a3b742a76cfb3e479a9b8f36895f-7833b2840b3962b8a17bf915594fbc0f from localhost/127.0.0.1:41055
2025-01-28 08:32:31,394 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@4fedfcc2
2025-01-28 08:32:31,396 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-01-28 08:32:31,404 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (64d05c2a988b298cf441ad83dec990f9) switched from DEPLOYING to INITIALIZING.
2025-01-28 08:32:31,576 WARN  org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer [] - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2025-01-28 08:32:31,579 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction [] - FlinkKafkaProducer 1/1 - no state to restore
2025-01-28 08:32:31,598 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2025-01-28 08:32:31,647 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'key.deserializer' was supplied but isn't a known config.
2025-01-28 08:32:31,648 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'value.deserializer' was supplied but isn't a known config.
2025-01-28 08:32:31,649 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'group.id' was supplied but isn't a known config.
2025-01-28 08:32:31,649 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2025-01-28 08:32:31,650 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.8.0
2025-01-28 08:32:31,651 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: ebb1d6e21cc92130
2025-01-28 08:32:31,651 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1738033351649
2025-01-28 08:32:31,652 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer [] - Starting FlinkKafkaInternalProducer (1/1) to produce into default topic output-topic
2025-01-28 08:32:31,668 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 has no restore state.
2025-01-28 08:32:31,677 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-consumer-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-01-28 08:32:31,715 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'value.serializer' was supplied but isn't a known config.
2025-01-28 08:32:31,715 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2025-01-28 08:32:31,715 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'key.serializer' was supplied but isn't a known config.
2025-01-28 08:32:31,715 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.8.0
2025-01-28 08:32:31,715 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: ebb1d6e21cc92130
2025-01-28 08:32:31,715 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1738033351715
2025-01-28 08:32:31,907 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-flink-consumer-group-1, groupId=flink-consumer-group] Cluster ID: TZiD9Jf9QjuqeII8xKPItw
2025-01-28 08:32:31,907 INFO  org.apache.kafka.clients.Metadata                            [] - [Producer clientId=producer-1] Cluster ID: TZiD9Jf9QjuqeII8xKPItw
2025-01-28 08:32:32,371 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='input-topic', partition=0}]
2025-01-28 08:32:32,372 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (64d05c2a988b298cf441ad83dec990f9) switched from INITIALIZING to RUNNING.
2025-01-28 08:32:32,376 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='input-topic', partition=0}=-915623761773}.
2025-01-28 08:32:32,380 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-consumer-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-01-28 08:32:32,385 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'value.serializer' was supplied but isn't a known config.
2025-01-28 08:32:32,385 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2025-01-28 08:32:32,385 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'key.serializer' was supplied but isn't a known config.
2025-01-28 08:32:32,386 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.8.0
2025-01-28 08:32:32,386 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: ebb1d6e21cc92130
2025-01-28 08:32:32,386 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1738033352385
2025-01-28 08:32:32,387 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=consumer-flink-consumer-group-2, groupId=flink-consumer-group] Subscribed to partition(s): input-topic-0
2025-01-28 08:32:32,400 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-flink-consumer-group-2, groupId=flink-consumer-group] Cluster ID: TZiD9Jf9QjuqeII8xKPItw
2025-01-28 08:32:33,449 INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator [] - [Consumer clientId=consumer-flink-consumer-group-2, groupId=flink-consumer-group] Discovered group coordinator hansaka-ubuntu:9092 (id: 2147483647 rack: null)
2025-01-28 08:32:33,464 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-flink-consumer-group-2, groupId=flink-consumer-group] Found no committed offset for partition input-topic-0
2025-01-28 08:32:33,474 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=consumer-flink-consumer-group-2, groupId=flink-consumer-group] Resetting offset for partition input-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[hansaka-ubuntu:9092 (id: 0 rack: null)], epoch=0}}.
2025-01-28 08:42:08,821 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Error while fetching metadata with correlation id 5 : {output-topic=LEADER_NOT_AVAILABLE}
2025-01-28 08:44:30,736 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (64d05c2a988b298cf441ad83dec990f9).
2025-01-28 08:44:30,736 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (64d05c2a988b298cf441ad83dec990f9) switched from RUNNING to CANCELING.
2025-01-28 08:44:30,737 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (64d05c2a988b298cf441ad83dec990f9).
2025-01-28 08:44:30,743 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-01-28 08:44:30,744 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-28 08:44:30,744 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-01-28 08:44:30,745 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 0 ms.
2025-01-28 08:44:30,745 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-1] Proceeding to force close the producer since pending requests could not be completed within timeout 0 ms.
2025-01-28 08:44:30,754 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for consumer-flink-consumer-group-2 unregistered
2025-01-28 08:44:30,759 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-01-28 08:44:30,759 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-28 08:44:30,759 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-01-28 08:44:30,760 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-1 unregistered
2025-01-28 08:44:30,761 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2025-01-28 08:44:30,761 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-01-28 08:44:30,761 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2025-01-28 08:44:30,764 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for consumer-flink-consumer-group-1 unregistered
2025-01-28 08:44:30,770 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (64d05c2a988b298cf441ad83dec990f9) switched from CANCELING to CANCELED.
2025-01-28 08:44:30,770 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (64d05c2a988b298cf441ad83dec990f9).
2025-01-28 08:44:30,772 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 64d05c2a988b298cf441ad83dec990f9.
2025-01-28 08:44:30,798 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:0, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1.0000000000000000, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}, allocationId: d2c93e2be0aceb0ecda0478f437ae702, jobId: 64a213c6b566eaf4a6e1a5e76640b445).
2025-01-28 08:44:30,801 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job 64a213c6b566eaf4a6e1a5e76640b445 from job leader monitoring.
2025-01-28 08:44:30,801 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job 64a213c6b566eaf4a6e1a5e76640b445.
2025-01-28 08:44:55,056 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request c7be569114fb2b1bd51f4fc6ce4858e6 for job c73706ca261d34b8b411b8af322738a6 from resource manager with leader id 00000000000000000000000000000000.
2025-01-28 08:44:55,057 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for c7be569114fb2b1bd51f4fc6ce4858e6.
2025-01-28 08:44:55,057 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job c73706ca261d34b8b411b8af322738a6 for job leader monitoring.
2025-01-28 08:44:55,057 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager akka.tcp://flink@localhost:6123/user/rpc/jobmanager_4 with leader id 00000000-0000-0000-0000-000000000000.
2025-01-28 08:44:55,062 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-01-28 08:44:55,071 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager akka.tcp://flink@localhost:6123/user/rpc/jobmanager_4 for job c73706ca261d34b8b411b8af322738a6.
2025-01-28 08:44:55,071 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job c73706ca261d34b8b411b8af322738a6.
2025-01-28 08:44:55,071 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job c73706ca261d34b8b411b8af322738a6.
2025-01-28 08:44:55,082 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot c7be569114fb2b1bd51f4fc6ce4858e6.
2025-01-28 08:44:55,085 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (be7e0fbc0c33861a16246a696117cc0c), deploy into slot with allocation id c7be569114fb2b1bd51f4fc6ce4858e6.
2025-01-28 08:44:55,086 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (be7e0fbc0c33861a16246a696117cc0c) switched from CREATED to DEPLOYING.
2025-01-28 08:44:55,088 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (be7e0fbc0c33861a16246a696117cc0c) [DEPLOYING].
2025-01-28 08:44:55,087 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot c7be569114fb2b1bd51f4fc6ce4858e6.
2025-01-28 08:44:55,089 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading c73706ca261d34b8b411b8af322738a6/p-b3b6e47ee9f7a3b742a76cfb3e479a9b8f36895f-af099cef47bfe1c4c8a18e87cc656c1b from localhost/127.0.0.1:41055
2025-01-28 08:44:55,406 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@14616381
2025-01-28 08:44:55,406 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-01-28 08:44:55,406 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (be7e0fbc0c33861a16246a696117cc0c) switched from DEPLOYING to INITIALIZING.
2025-01-28 08:44:55,439 WARN  org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer [] - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2025-01-28 08:44:55,440 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction [] - FlinkKafkaProducer 1/1 - no state to restore
2025-01-28 08:44:55,459 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2025-01-28 08:44:55,498 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'key.deserializer' was supplied but isn't a known config.
2025-01-28 08:44:55,500 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'value.deserializer' was supplied but isn't a known config.
2025-01-28 08:44:55,500 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'group.id' was supplied but isn't a known config.
2025-01-28 08:44:55,500 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2025-01-28 08:44:55,501 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.8.0
2025-01-28 08:44:55,501 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: ebb1d6e21cc92130
2025-01-28 08:44:55,501 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1738034095500
2025-01-28 08:44:55,502 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer [] - Starting FlinkKafkaInternalProducer (1/1) to produce into default topic output-topic
2025-01-28 08:44:55,506 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 has no restore state.
2025-01-28 08:44:55,514 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-consumer-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-01-28 08:44:55,548 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'value.serializer' was supplied but isn't a known config.
2025-01-28 08:44:55,548 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2025-01-28 08:44:55,548 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'key.serializer' was supplied but isn't a known config.
2025-01-28 08:44:55,548 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.8.0
2025-01-28 08:44:55,548 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: ebb1d6e21cc92130
2025-01-28 08:44:55,548 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1738034095548
2025-01-28 08:44:55,725 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-flink-consumer-group-1, groupId=flink-consumer-group] Cluster ID: TZiD9Jf9QjuqeII8xKPItw
2025-01-28 08:44:55,725 INFO  org.apache.kafka.clients.Metadata                            [] - [Producer clientId=producer-1] Cluster ID: TZiD9Jf9QjuqeII8xKPItw
2025-01-28 08:44:55,727 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='input-topic', partition=0}]
2025-01-28 08:44:55,728 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (be7e0fbc0c33861a16246a696117cc0c) switched from INITIALIZING to RUNNING.
2025-01-28 08:44:55,730 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='input-topic', partition=0}=-915623761773}.
2025-01-28 08:44:55,737 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-consumer-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-01-28 08:44:55,741 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'value.serializer' was supplied but isn't a known config.
2025-01-28 08:44:55,741 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2025-01-28 08:44:55,741 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'key.serializer' was supplied but isn't a known config.
2025-01-28 08:44:55,741 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.8.0
2025-01-28 08:44:55,741 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: ebb1d6e21cc92130
2025-01-28 08:44:55,741 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1738034095741
2025-01-28 08:44:55,742 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=consumer-flink-consumer-group-2, groupId=flink-consumer-group] Subscribed to partition(s): input-topic-0
2025-01-28 08:44:55,749 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-flink-consumer-group-2, groupId=flink-consumer-group] Cluster ID: TZiD9Jf9QjuqeII8xKPItw
2025-01-28 08:44:55,750 INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator [] - [Consumer clientId=consumer-flink-consumer-group-2, groupId=flink-consumer-group] Discovered group coordinator hansaka-ubuntu:9092 (id: 2147483647 rack: null)
2025-01-28 08:44:55,756 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-flink-consumer-group-2, groupId=flink-consumer-group] Setting offset for partition input-topic-0 to the committed offset FetchPosition{offset=326, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[hansaka-ubuntu:9092 (id: 0 rack: null)], epoch=0}}
2025-01-28 09:10:29,465 INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator [] - [Consumer clientId=consumer-flink-consumer-group-2, groupId=flink-consumer-group] Group coordinator hansaka-ubuntu:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
2025-01-28 09:10:30,049 INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator [] - [Consumer clientId=consumer-flink-consumer-group-2, groupId=flink-consumer-group] Discovered group coordinator hansaka-ubuntu:9092 (id: 2147483647 rack: null)
