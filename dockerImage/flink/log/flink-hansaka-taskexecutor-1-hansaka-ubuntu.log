2025-02-01 14:02:22,112 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - --------------------------------------------------------------------------------
2025-02-01 14:02:22,113 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Preconfiguration: 
2025-02-01 14:02:22,113 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - 


RESOURCE_PARAMS extraction logs:
jvm_params: -Xmx536870902 -Xms536870902 -XX:MaxDirectMemorySize=268435458 -XX:MaxMetaspaceSize=268435456
dynamic_configs: -D taskmanager.memory.network.min=134217730b -D taskmanager.cpu.cores=1.0 -D taskmanager.memory.task.off-heap.size=0b -D taskmanager.memory.jvm-metaspace.size=268435456b -D external-resources=none -D taskmanager.memory.jvm-overhead.min=201326592b -D taskmanager.memory.framework.off-heap.size=134217728b -D taskmanager.memory.network.max=134217730b -D taskmanager.memory.framework.heap.size=134217728b -D taskmanager.memory.managed.size=536870920b -D taskmanager.memory.task.heap.size=402653174b -D taskmanager.numberOfTaskSlots=1 -D taskmanager.memory.jvm-overhead.max=201326592b
logs: WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.
INFO  [] - Loading configuration property: jobmanager.rpc.address, localhost
INFO  [] - Loading configuration property: jobmanager.rpc.port, 6123
INFO  [] - Loading configuration property: jobmanager.memory.process.size, 1600m
INFO  [] - Loading configuration property: taskmanager.memory.process.size, 1728m
INFO  [] - Loading configuration property: taskmanager.numberOfTaskSlots, 1
INFO  [] - Loading configuration property: parallelism.default, 1
INFO  [] - Loading configuration property: jobmanager.execution.failover-strategy, region
INFO  [] - Loading configuration property: metrics.reporters, prometheus
INFO  [] - Loading configuration property: metrics.reporter.prometheus.class, org.apache.flink.metrics.prometheus.PrometheusReporter
INFO  [] - Loading configuration property: metrics.reporter.prometheus.host, "0.0.0.0"
INFO  [] - Loading configuration property: metrics.reporter.prometheus.port, 9249
INFO  [] - Loading configuration property: metrics.reporters, prometheus
INFO  [] - Loading configuration property: metrics.reporter.prometheus.class, org.apache.flink.metrics.prometheus.PrometheusReporter
INFO  [] - Loading configuration property: metrics.reporter.prometheus.host, "112.134.231.79"
INFO  [] - Loading configuration property: metrics.reporter.prometheus.port, 9249
INFO  [] - The derived from fraction jvm overhead memory (172.800mb (181193935 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead
INFO  [] - Final TaskExecutor Memory configuration:
INFO  [] -   Total Process Memory:          1.688gb (1811939328 bytes)
INFO  [] -     Total Flink Memory:          1.250gb (1342177280 bytes)
INFO  [] -       Total JVM Heap Memory:     512.000mb (536870902 bytes)
INFO  [] -         Framework:               128.000mb (134217728 bytes)
INFO  [] -         Task:                    384.000mb (402653174 bytes)
INFO  [] -       Total Off-heap Memory:     768.000mb (805306378 bytes)
INFO  [] -         Managed:                 512.000mb (536870920 bytes)
INFO  [] -         Total JVM Direct Memory: 256.000mb (268435458 bytes)
INFO  [] -           Framework:             128.000mb (134217728 bytes)
INFO  [] -           Task:                  0 bytes
INFO  [] -           Network:               128.000mb (134217730 bytes)
INFO  [] -     JVM Metaspace:               256.000mb (268435456 bytes)
INFO  [] -     JVM Overhead:                192.000mb (201326592 bytes)

2025-02-01 14:02:22,114 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - --------------------------------------------------------------------------------
2025-02-01 14:02:22,114 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Starting TaskManager (Version: 1.13.6, Scala: 2.12, Rev:b2ca390, Date:2022-02-03T14:54:22+01:00)
2025-02-01 14:02:22,114 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  OS current user: hansaka
2025-02-01 14:02:22,114 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Current Hadoop/Kerberos user: <no hadoop dependency found>
2025-02-01 14:02:22,114 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  JVM: OpenJDK 64-Bit Server VM - Ubuntu - 11/11.0.25+9-post-Ubuntu-1ubuntu122.04
2025-02-01 14:02:22,114 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Maximum heap size: 512 MiBytes
2025-02-01 14:02:22,114 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  JAVA_HOME: (not set)
2025-02-01 14:02:22,114 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  No Hadoop Dependency available
2025-02-01 14:02:22,114 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  JVM Options:
2025-02-01 14:02:22,114 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -XX:+UseG1GC
2025-02-01 14:02:22,114 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Xmx536870902
2025-02-01 14:02:22,114 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Xms536870902
2025-02-01 14:02:22,114 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -XX:MaxDirectMemorySize=268435458
2025-02-01 14:02:22,114 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -XX:MaxMetaspaceSize=268435456
2025-02-01 14:02:22,114 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlog.file=/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/log/flink-hansaka-taskexecutor-1-hansaka-ubuntu.log
2025-02-01 14:02:22,114 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlog4j.configuration=file:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/conf/log4j.properties
2025-02-01 14:02:22,115 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlog4j.configurationFile=file:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/conf/log4j.properties
2025-02-01 14:02:22,115 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlogback.configurationFile=file:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/conf/logback.xml
2025-02-01 14:02:22,115 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Program Arguments:
2025-02-01 14:02:22,115 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --configDir
2025-02-01 14:02:22,115 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     /home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/conf
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.network.min=134217730b
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.cpu.cores=1.0
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.task.off-heap.size=0b
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.jvm-metaspace.size=268435456b
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     external-resources=none
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.jvm-overhead.min=201326592b
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.framework.off-heap.size=134217728b
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.network.max=134217730b
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.framework.heap.size=134217728b
2025-02-01 14:02:22,116 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-02-01 14:02:22,117 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.managed.size=536870920b
2025-02-01 14:02:22,117 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-02-01 14:02:22,117 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.task.heap.size=402653174b
2025-02-01 14:02:22,117 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-02-01 14:02:22,117 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.numberOfTaskSlots=1
2025-02-01 14:02:22,117 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2025-02-01 14:02:22,117 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.jvm-overhead.max=201326592b
2025-02-01 14:02:22,117 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Classpath: /home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/flink-csv-1.13.6.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/flink-json-1.13.6.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/flink-shaded-zookeeper-3.4.14.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/flink-table_2.12-1.13.6.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/flink-table-blink_2.12-1.13.6.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/log4j-1.2-api-2.17.1.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/log4j-api-2.17.1.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/log4j-core-2.17.1.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/log4j-slf4j-impl-2.17.1.jar:/home/hansaka/fyp/EDFLY/withJSON/flink-1.13.6/lib/flink-dist_2.12-1.13.6.jar:::
2025-02-01 14:02:22,117 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - --------------------------------------------------------------------------------
2025-02-01 14:02:22,118 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Registered UNIX signal handlers for [TERM, HUP, INT]
2025-02-01 14:02:22,119 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Maximum number of open file descriptors is 1048576.
2025-02-01 14:02:22,124 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, localhost
2025-02-01 14:02:22,124 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.port, 6123
2025-02-01 14:02:22,125 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 1600m
2025-02-01 14:02:22,125 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 1728m
2025-02-01 14:02:22,125 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 1
2025-02-01 14:02:22,125 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 1
2025-02-01 14:02:22,125 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.execution.failover-strategy, region
2025-02-01 14:02:22,125 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporters, prometheus
2025-02-01 14:02:22,125 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.prometheus.class, org.apache.flink.metrics.prometheus.PrometheusReporter
2025-02-01 14:02:22,125 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.prometheus.host, "0.0.0.0"
2025-02-01 14:02:22,126 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.prometheus.port, 9249
2025-02-01 14:02:22,126 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporters, prometheus
2025-02-01 14:02:22,126 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.prometheus.class, org.apache.flink.metrics.prometheus.PrometheusReporter
2025-02-01 14:02:22,126 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.prometheus.host, "112.134.231.79"
2025-02-01 14:02:22,126 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: metrics.reporter.prometheus.port, 9249
2025-02-01 14:02:22,154 INFO  org.apache.flink.core.fs.FileSystem                          [] - Hadoop is not in the classpath/dependencies. The extended set of supported File Systems via Hadoop is not available.
2025-02-01 14:02:22,181 INFO  org.apache.flink.runtime.security.modules.HadoopModuleFactory [] - Cannot create Hadoop Security Module because Hadoop cannot be found in the Classpath.
2025-02-01 14:02:22,190 INFO  org.apache.flink.runtime.security.modules.JaasModule         [] - Jaas file will be created as /tmp/jaas-7597877021049017688.conf.
2025-02-01 14:02:22,195 INFO  org.apache.flink.runtime.security.contexts.HadoopSecurityContextFactory [] - Cannot install HadoopSecurityContext because Hadoop cannot be found in the Classpath.
2025-02-01 14:02:22,246 INFO  org.apache.flink.configuration.Configuration                 [] - Config uses fallback configuration key 'jobmanager.rpc.address' instead of key 'rest.address'
2025-02-01 14:02:22,256 INFO  org.apache.flink.runtime.util.LeaderRetrievalUtils           [] - Trying to select the network interface and address to use by connecting to the leading JobManager.
2025-02-01 14:02:22,256 INFO  org.apache.flink.runtime.util.LeaderRetrievalUtils           [] - TaskManager will try to connect for PT10S before falling back to heuristics
2025-02-01 14:02:22,341 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - TaskManager will use hostname/address 'hansaka-ubuntu' (192.168.1.12) for communication.
2025-02-01 14:02:22,346 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address 192.168.1.12:0, bind address 0.0.0.0:0.
2025-02-01 14:02:22,792 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2025-02-01 14:02:22,817 INFO  akka.remote.Remoting                                         [] - Starting remoting
2025-02-01 14:02:22,987 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink@192.168.1.12:41459]
2025-02-01 14:02:23,066 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink@192.168.1.12:41459
2025-02-01 14:02:23,115 ERROR org.apache.flink.runtime.metrics.ReporterSetup               [] - Could not instantiate metrics reporter prometheus. Metrics might not be exposed/reported.
java.lang.RuntimeException: Could not start PrometheusReporter HTTP server on any configured port. Ports: org.apache.flink.util.UnionIterator@cb0f763
	at org.apache.flink.metrics.prometheus.PrometheusReporter.<init>(PrometheusReporter.java:62) ~[?:?]
	at org.apache.flink.metrics.prometheus.PrometheusReporterFactory.createMetricReporter(PrometheusReporterFactory.java:42) ~[?:?]
	at org.apache.flink.metrics.prometheus.PrometheusReporterFactory.createMetricReporter(PrometheusReporterFactory.java:29) ~[?:?]
	at org.apache.flink.runtime.metrics.ReporterSetup.loadViaFactory(ReporterSetup.java:378) ~[flink-dist_2.12-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.metrics.ReporterSetup.loadReporter(ReporterSetup.java:339) ~[flink-dist_2.12-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.metrics.ReporterSetup.setupReporters(ReporterSetup.java:286) ~[flink-dist_2.12-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.metrics.ReporterSetup.fromConfiguration(ReporterSetup.java:167) ~[flink-dist_2.12-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskexecutor.TaskManagerRunner.<init>(TaskManagerRunner.java:161) ~[flink-dist_2.12-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskexecutor.TaskManagerRunner.runTaskManager(TaskManagerRunner.java:362) ~[flink-dist_2.12-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskexecutor.TaskManagerRunner.lambda$runTaskManagerProcessSecurely$3(TaskManagerRunner.java:408) ~[flink-dist_2.12-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.security.contexts.NoOpSecurityContext.runSecured(NoOpSecurityContext.java:28) [flink-dist_2.12-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskexecutor.TaskManagerRunner.runTaskManagerProcessSecurely(TaskManagerRunner.java:408) [flink-dist_2.12-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskexecutor.TaskManagerRunner.runTaskManagerProcessSecurely(TaskManagerRunner.java:391) [flink-dist_2.12-1.13.6.jar:1.13.6]
	at org.apache.flink.runtime.taskexecutor.TaskManagerRunner.main(TaskManagerRunner.java:349) [flink-dist_2.12-1.13.6.jar:1.13.6]
2025-02-01 14:02:23,118 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No metrics reporter configured, no metrics will be exposed/reported.
2025-02-01 14:02:23,125 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address 192.168.1.12:0, bind address 0.0.0.0:0.
2025-02-01 14:02:23,136 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2025-02-01 14:02:23,139 INFO  akka.remote.Remoting                                         [] - Starting remoting
2025-02-01 14:02:23,146 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink-metrics@192.168.1.12:40779]
2025-02-01 14:02:23,152 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink-metrics@192.168.1.12:40779
2025-02-01 14:02:23,168 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService_192.168.1.12:41459-f6f116 .
2025-02-01 14:02:23,175 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Created BLOB cache storage directory /tmp/blobStore-d71400e3-a938-451c-b4ff-3e55160d8df4
2025-02-01 14:02:23,177 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Created BLOB cache storage directory /tmp/blobStore-9ab9b100-06ef-4b01-8496-85ea1a36f41b
2025-02-01 14:02:23,178 INFO  org.apache.flink.runtime.externalresource.ExternalResourceUtils [] - Enabled external resources: []
2025-02-01 14:02:23,179 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Starting TaskManager with ResourceID: 192.168.1.12:41459-f6f116
2025-02-01 14:02:23,199 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/tmp': total 115 GB, usable 11 GB (9.57% usable)
2025-02-01 14:02:23,204 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /tmp/flink-io-c32f48a0-16ad-4672-9507-c0de4c2e0dfc for spill files.
2025-02-01 14:02:23,216 INFO  org.apache.flink.runtime.io.network.netty.NettyConfig        [] - NettyConfig [server address: /0.0.0.0, server port: 0, ssl enabled: false, memory segment size (bytes): 32768, transport type: AUTO, number of server threads: 1 (manual), number of client threads: 1 (manual), server connect backlog: 0 (use Netty's default), client connect timeout (sec): 120, send/receive buffer size (bytes): 0 (use Netty's default)]
2025-02-01 14:02:23,220 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory /tmp/flink-netty-shuffle-4a5049a5-2a7c-4686-b72d-faaf13ce4363 for spill files.
2025-02-01 14:02:23,346 INFO  org.apache.flink.runtime.io.network.buffer.NetworkBufferPool [] - Allocated 128 MB for network buffer pool (number of memory segments: 4096, bytes per segment: 32768).
2025-02-01 14:02:23,355 INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment  [] - Starting the network environment and its components.
2025-02-01 14:02:23,418 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Transport type 'auto': using EPOLL.
2025-02-01 14:02:23,419 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Successful initialization (took 63 ms).
2025-02-01 14:02:23,422 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Transport type 'auto': using EPOLL.
2025-02-01 14:02:23,445 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Successful initialization (took 25 ms). Listening on SocketAddress /0:0:0:0:0:0:0:0%0:45729.
2025-02-01 14:02:23,447 INFO  org.apache.flink.runtime.taskexecutor.KvStateService         [] - Starting the kvState service and its components.
2025-02-01 14:02:23,470 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2025-02-01 14:02:23,487 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Start job leader service.
2025-02-01 14:02:23,488 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /tmp/flink-dist-cache-09cfa6bb-9711-408c-97e6-432879215f34
2025-02-01 14:02:23,490 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Connecting to ResourceManager akka.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000).
2025-02-01 14:02:23,614 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Resolved ResourceManager address, beginning registration
2025-02-01 14:02:23,643 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Successful registration at resource manager akka.tcp://flink@localhost:6123/user/rpc/resourcemanager_* under registration id 06f14a62c11c0cccfbce82cb29bfd330.
2025-02-01 14:02:59,558 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request f0ec7c569cfca127cdf8a927ebf8f5c0 for job 2327769b2db50134023f16beaa82f78a from resource manager with leader id 00000000000000000000000000000000.
2025-02-01 14:02:59,614 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for f0ec7c569cfca127cdf8a927ebf8f5c0.
2025-02-01 14:02:59,615 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job 2327769b2db50134023f16beaa82f78a for job leader monitoring.
2025-02-01 14:02:59,616 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager akka.tcp://flink@localhost:6123/user/rpc/jobmanager_3 with leader id 00000000-0000-0000-0000-000000000000.
2025-02-01 14:02:59,814 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2025-02-01 14:02:59,826 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager akka.tcp://flink@localhost:6123/user/rpc/jobmanager_3 for job 2327769b2db50134023f16beaa82f78a.
2025-02-01 14:02:59,827 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job 2327769b2db50134023f16beaa82f78a.
2025-02-01 14:02:59,830 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job 2327769b2db50134023f16beaa82f78a.
2025-02-01 14:02:59,840 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot f0ec7c569cfca127cdf8a927ebf8f5c0.
2025-02-01 14:02:59,843 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot f0ec7c569cfca127cdf8a927ebf8f5c0.
2025-02-01 14:02:59,867 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (af10b297edf2af527deac28df0d32da0), deploy into slot with allocation id f0ec7c569cfca127cdf8a927ebf8f5c0.
2025-02-01 14:02:59,867 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (af10b297edf2af527deac28df0d32da0) switched from CREATED to DEPLOYING.
2025-02-01 14:02:59,870 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (af10b297edf2af527deac28df0d32da0) [DEPLOYING].
2025-02-01 14:02:59,873 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading 2327769b2db50134023f16beaa82f78a/p-b3b6e47ee9f7a3b742a76cfb3e479a9b8f36895f-ef911f79b6929b543b3a005cef74ceb8 from localhost/127.0.0.1:38571
2025-02-01 14:03:02,941 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@19948afe
2025-02-01 14:03:03,004 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2025-02-01 14:03:04,015 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (af10b297edf2af527deac28df0d32da0) switched from DEPLOYING to INITIALIZING.
2025-02-01 14:03:08,530 WARN  org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer [] - Using AT_LEAST_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2025-02-01 14:03:09,029 INFO  org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction [] - FlinkKafkaProducer 1/1 - no state to restore
2025-02-01 14:03:09,042 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2025-02-01 14:03:09,073 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'key.deserializer' was supplied but isn't a known config.
2025-02-01 14:03:09,074 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'value.deserializer' was supplied but isn't a known config.
2025-02-01 14:03:09,074 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'group.id' was supplied but isn't a known config.
2025-02-01 14:03:09,074 WARN  org.apache.kafka.clients.producer.ProducerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2025-02-01 14:03:09,075 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.8.0
2025-02-01 14:03:09,075 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: ebb1d6e21cc92130
2025-02-01 14:03:09,075 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1738398789074
2025-02-01 14:03:09,076 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer [] - Starting FlinkKafkaInternalProducer (1/1) to produce into default topic output-topic
2025-02-01 14:03:09,557 INFO  org.apache.kafka.clients.Metadata                            [] - [Producer clientId=producer-1] Cluster ID: M27Y-j0mReaHKWwHBd83wA
2025-02-01 14:03:10,547 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 has no restore state.
2025-02-01 14:03:10,553 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-consumer-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-02-01 14:03:10,581 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'value.serializer' was supplied but isn't a known config.
2025-02-01 14:03:10,581 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2025-02-01 14:03:10,581 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'key.serializer' was supplied but isn't a known config.
2025-02-01 14:03:10,581 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.8.0
2025-02-01 14:03:10,581 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: ebb1d6e21cc92130
2025-02-01 14:03:10,581 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1738398790581
2025-02-01 14:03:10,586 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-flink-consumer-group-1, groupId=flink-consumer-group] Cluster ID: M27Y-j0mReaHKWwHBd83wA
2025-02-01 14:03:10,589 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='input-topic', partition=0}]
2025-02-01 14:03:10,591 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Map -> Sink: Unnamed (1/1)#0 (af10b297edf2af527deac28df0d32da0) switched from INITIALIZING to RUNNING.
2025-02-01 14:03:10,593 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='input-topic', partition=0}=-915623761773}.
2025-02-01 14:03:10,597 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-flink-consumer-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2025-02-01 14:03:10,602 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'value.serializer' was supplied but isn't a known config.
2025-02-01 14:03:10,603 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'transaction.timeout.ms' was supplied but isn't a known config.
2025-02-01 14:03:10,603 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'key.serializer' was supplied but isn't a known config.
2025-02-01 14:03:10,603 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 2.8.0
2025-02-01 14:03:10,603 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: ebb1d6e21cc92130
2025-02-01 14:03:10,603 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1738398790603
2025-02-01 14:03:10,605 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=consumer-flink-consumer-group-2, groupId=flink-consumer-group] Subscribed to partition(s): input-topic-0
2025-02-01 14:03:10,613 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-flink-consumer-group-2, groupId=flink-consumer-group] Cluster ID: M27Y-j0mReaHKWwHBd83wA
2025-02-01 14:03:10,615 INFO  org.apache.kafka.clients.consumer.internals.AbstractCoordinator [] - [Consumer clientId=consumer-flink-consumer-group-2, groupId=flink-consumer-group] Discovered group coordinator hansaka-ubuntu:9092 (id: 2147483647 rack: null)
2025-02-01 14:03:10,625 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-flink-consumer-group-2, groupId=flink-consumer-group] Setting offset for partition input-topic-0 to the committed offset FetchPosition{offset=395, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[hansaka-ubuntu:9092 (id: 0 rack: null)], epoch=0}}
